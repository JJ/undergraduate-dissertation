#+TITLE: Small Disjuncts
#+AUTHOR: Ignacio Cordón Castillo
#+OPTIONS: toc:t
#+LANGUAGE: es
#+STARTUP: latexpreview
#+STARTUP: indent
#+DATE:
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \input{titlepage}
#+LATEX_HEADER: \usepackage{amsmath} 
#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \newtheorem*{theorem}{Teorema}
#+LATEX_HEADER: \newtheorem*{fact}{Proposición}
#+LATEX_HEADER: \newtheorem*{corollary}{Corolario}
#+LATEX_HEADER: \newtheorem*{definition}{Definición}
#+LATEX_HEADER: \setlength{\parindent}{0pt}
#+LATEX_HEADER: \setlength{\parskip}{1em}
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \newenvironment{wording}{\setlength{\parskip}{0pt}\rule{\textwidth}{0.5em}}{~\\\rule{\textwidth}{0.5em}}
#+LATEX_HEADER: \everymath{\displaystyle}

\break
* Introducción

El problema de la clasificación consiste en datos un conjunto de datos...

Cualquier distribución desbalanceada de clases en el problema de la clasificación puede considerarse un problema de clasificación con desbalanceo, pero suele considerarse por convención que hay desbalanceo cuando hay ratios de representación de clases de 1:100, 1:1000, 1:10000. Los ratios no tienen por qué referirse únicamente a clasificación binaria, sino que pueden afectar a problemas multiclase.

En muchas ocasiones, al realizar análisis de datos no se tiene en cuenta el desbalanceo existente entre clases, lo cual hace que los algoritmos no reflejen adecuadamente la distribución de clases. Esto provoca que los algoritmos, en los ejemplos en que nos interesa una ratio de predicción acertada alto en la clase minoritaria, no tengan los resultados deseado.

El desbalanceo puede ser intrínseco, cuando lo que da lugar al mismo es la naturaleza del espacio de muestreo, y extrínseco, en caso de que los desbalanceos se produzcan por factores externos a la naturaleza del espacio de muestreo como restricciones de almacenamiento y capacidad de muestreo.

Puede asimismo hacerse una distinción de desbalanceo como desbalanceo relativo y desbalanceo debido a instancias raras (/absolute rarity/). El desbalanceo relativo es aquel en que la función de distribución de la clases se conserva al tomar varias muestras aleatorias simples, el desbalanceo debido a instancias raras no, y éste último está estrechamente relacionado con el desbalanceo intra-clases (/within-class/) debido a la distribución en distintos /clusters/ de instancias de una misma clase en el espacio de exploración. La falta de representatividad de la distribución de clases por parte del clasificador no sólo se debe al desbalanceo de clases, sino que se puede deber a un amplio rango de factores que afectan a la complejidad de los datos (/overlapping/, falta de representatividad en los datos, /small disjuncts/, etc).

El desbalanceo intra-clases se encuentra estrechamente relacionado con el problema de los /small-disjuncts/. En general, los clasificadores intentan aprender a partir de una clase creando reglas disjuntas que afecten a /clusters/ de instancias. Como consecuencia de la infrarrepresentación de instancias en el caso de clases heterogéneas (repartidas en varios /clusters/), podemos tener reglas que cubren una pequeña porción de las instancias de una clase, esto es /small-disjuncts/. Los /small-disjuncts/ no sólo afectan a la clase minoritaria, sino que pueden darse también dentro de la mayoritaria, aunque la mayor densidad de datos de esta clase hace que el efecto no sea tan agravado o sea una situación menos frecuente. El gran desafío en la identificación de los /small-disjunts/ es identificar todas las agrupaciones minoritarias de una clase, sin generar también reglas de clasificación para los datos que representan ruido. Por tanto, en problemas con alta dimensionalidad y baja densidad de muestreo, también encontramos /small-disjunts/.

* Notación

\[S=\{(x_{i,1}, \ldots x_{i,m}, y_i)\, i=1,\ldots m \}\]
\[(x_{i,1}, \ldots x_{i,m})\in X\]
\[y_i \in \{1\ldots C\}\]

con $S$ muestra aleatoria de una variable, $X$ espacio de características e $Y$ conjunto de clases finito con $C\ge 2$.

Notamos $S_{min}$ a los ejemplos de la clase minoritaria, $S_{maj}$ a los de la mayoritaria. Se verifica $S_{min}\cap S_{maj} = \emptyset$

Llamamos $E$ al conjunto de instancias generadas mediante técnicas de /sampling/ y $E_{maj}$, $E_{min}$ a las etiquetadas como de las clases mayoritaria y minoritaria, respectivamente.

* Oversampling y undersampling

En el /oversampling/ seleccionamos un conjunto $E\subseteq S_{min}$ y lo adherimos a $S_{min}$. El /undersampling/ consiste en eliminar un subconjunto de $S_{maj}$

* Métodos basados en kernel y métodos de aprendizaje activo

** Framework de aprendizaje basado en núcleo

*** SVMs
Problema de las máquinas de soporte de vectores es que tienden a clasificar los ejemplos como pertenecientes a la clase mayoritaria, para maximizar la tasa de acierto.

** Sampling hibridado con métodos basados en kernel

*** SDCs: SMOTE with different costs

*** Over/undersampled SVMs

*** SVMs con clasificación errónea asimétrica(SVMs with asymmetric misclassification)

*** Granular Support Vector Machines (GSVMs)

Se basan en los principios de la teoría del aprendizaje estadístico y de la teoría de computación granular.

Tienen como ventajas frente a los SVMs mejor eficiencia computacional, debido al uso de paralelismo.

Destacan en este grupo los **GSVM-RU**

** Métodos de modificación de kernels para aprendizaje desbalanceado

Se centran en modificar SVM. Hay un kernel basado a su vez en OFS y ROWLS.

*** OFS: Orthogonal Forward Selection

Integra ideas de LOO (*Leaving-One-Out*) y AUC (Área bajo la curva)

*** ROWLS: Orthogonal Weigthed Least Squares

Usado para asignar mayor peso a los ejemplos erróneos de la clase minoritaria.

*** Métodos para ajustar la frontera de los SVM: BM, BPs, CBA, KBA

Destaca especialmente KBA, que realiza una aproximación al problema modificando la matriz del kernel en el espacio de caracterísicas.

*** Método SVM basado en Kernel difuso (TAF-SVM)

Tiene como ventajas que maneja bien el *overfitting* debido a la *fuzzificación* de los datos de entrenamiento, su adaptabilidad a diferentes distribuciones

*** PSVM: SVM proximal $k$-categórica (k-category proximal support vector machine)

Tiene como gran ventaja su rapidez, puesto que su funcionamiento se basa en la resolución de un sistema de $k$ ecuaciones lineales.

*** Modificación de Raskutti y Kowalcyzk 

** Métodos de aprendizaje activo para aprendizaje desbalanceado

*** Aproximación SALH

La idea fundamental de este método es proporcionar un modelo genérico para la evolución de los clasificadores basados en programación genética, integrando el *subsamplimg* estocástico y una función de coste *Wilcoxon-Mann-Whitney(WMW)* modificada.


* Otros métodos para aprendizaje desbalanceado

** Aprendizaje de una clase (one-class learning)

Estudios han ilustrado que este tipo de métodos son muy efectivos para tratar con datasets tremendamente desbalanceados y con alta dimensionalidad.

** Mahalanobi-Taguchi System (MTS)



* Medida de la bondad de los métodos

|   | p     | n     |
| Y | TP    | FP    |
| N | FN    | TN    |
|   | $p_c$ | $n_c$ |


Donde $p$ y $n$ representan la verdadera clase: positiva y negativa, y $Y$, $N$ la clase de la hipótesis.

\[ Exactitud = \frac{TP+TN}{P_C+N_C} \hspace{3em} Ratio_{error} = 1 - Exactitud \]

En general estas dos medidas resultan suficientes para expresar la bondad de los métodos. Pero en algunos casos pueden resultar engañosas, y ser muy sensibles a cambios en los datos.

Por ejemplo, si un *dataset* tiene 95% de datos pertenecientes a la clase mayoritaria, y 5% a la minoritaria, si clasificáramos todos los ejemplos como de la clase mayoritaria, obtendríamos un 95% de precisión, pero no clasificaríamos bien ni un solo ejemplo de la clase minoritaria.

Por convenio llamaremos a la clase mayoritaria, clase positiva; y a la clase minoritaria, clase negativa.

Observamos que la exactitud tiene en cuenta tanto el total de la clase mayoritaria como minoritaria. Por tanto depende de la distribución de datos de nuestro *dataset*, y no va a ser una medida adecuada para medir la bondad de métodos de aprendizaje desbalanceado.

\begin{eqnarray}
&& Precision = \frac{TP}{TP+FP}\\
&& Recall = \frac{TP}{TP+FN}\\
&& F-Measure = \frac{(1+\beta)^2\cdot Recall \cdot Precision}{\beta^2\cdot Recall + Precision}
\end{eqnarray}


Donde $\beta$ indica un coeficiente para ajustar la importancia de la precisión frente a *Recall*:

\[ G-mean = \sqrt{\frac{TP}{TP+FN} \cdot \frac{TN}{TN+FP}} \]

- Precisión refleja la exactitud de los datos
- *Recall* refleja la completitud de los datos
