

\section{Motivación}

El objetivo del aprendizaje automático es convertir datos en conocimiento a través de un razonamiento inductivo, de manera que
proporcionándole datos a una máquina, seamos capaces de extraer un conocimiento (una generalización de los datos, que nos permita
inferir información a partir de nuevos datos). Surge la pregunta de por qué es necesario el aprendizaje automático o 
\textit{machine learning}, si la estadística también se encarga de obtener conocimiento a partir de unos datos.

\subsection{¿Por qué necesitamos \textit{machine learning}?}
\begin{enumerate}[i]
 \item Para resolver \textbf{tareas que requieren automatización}: entran dentro de esta categoría tanto aquellas tareas para
 las que no existe una axiomatización o un conocimiento exacto, como pueden ser el reconocimiento de dígitos o de voz, como 
 aquellas tareas que requieren del análisis de un gran número de datos, y quedan fuera de la capacidad humana para realizar
 un análisis estadístico manual por ejemplo. En el primer caso necesitamos apoyarnos en conocimiento auxiliar (por ejemplo, 
 un conjunto de dígitos o de muestras de voz preetiquetadas con los que poder comparar muestras sin etiquetar/clasificar); 
 en el segundo, se hace necsario el uso de una máquina para poder extraer conocimiento de todos los datos.
 
 \item \textbf{Tareas que requieren adaptatividad}: como puede ser el reconocimiento de texto, donde no hay un patrón único de
 escritura para cada persona, y necesitamos que el algoritmo pueda generalizar eso.
\end{enumerate}

\subsection{Áreas relacionadas con el aprendizaje}
Entre las áreas relacionadas con el aprendizaje automático, cabe mencionar:

\begin{enumerate}[i]
 \item \textbf{Inteligencia Artificial}
 \item \textbf{Algorítmica}: debemos analizar el tiempo asintótico de los algoritmos mediante los que aprende la máquina.
 \item \textbf{Inferencia}: entre las diferencias que podemos mencionar con la estadística convencional, destaca la necesidad de 
 programar las tareas, dado el volumen de datos con el que normalmente se trabaja, mientras que en muchos análisis estadísticos basta 
 lápiz y papel. También destaca la \textbf{independencia respecto a distribución} con la que se trabaja (no se asume una distribución
 determinada sobre los datos). La principal diferencia del aprendizaje automático respecto a la inferencia es que la inferencia
 se encarga de comprobar la validez de las hipótesis que propone el estadista, mientras que el algoritmo de 
 \textit{machine learning} genera hipótesis para unos datos determinados, con unas ciertas condiciones de aproximación y error.
 \item \textbf{Álgebra lineal}
 \item \textbf{Optimización de algoritmos}
\end{enumerate}

\subsection{Ejemplo práctico}\label{sec:first-ex}
Pensemos en un ejemplo: tenemos clientes de un banco que quieren solicitar un préstamo, y a todos se les categoriza
el nivel de ingresos y el tamaño del préstamo (cómo de grande es su importe). Estas variables se miden 
en una escala de $0$ a $1$ donde $1$ es el nivel máximo. Queremos etiquetar a cada cliente como $S$:conceder préstamo o 
$N$:no conceder préstamo. Identificamos $0\equiv N$ y $1\equiv S$.

Dado un histórico de $m\in \mathbb{N}$ clientes a los que se les concedieron y devolvieron o no préstamos, tenemos una tupla 
$((x_1, y_1), \ldots (x_m, y_m))$ donde $x_i = ((x_i)_1, (x_i)_2) \in [0,1]^2$ y $y_i \in \{0,1\}$, y $(x_i)_1$ representa el nivel 
ingresos mensuales, y $(x_i)_2$ el tamaño del préstamo solicitado. Tenemos a los clientes clasificados en función de si 
devolvieron los préstamos o no.

Quiero encontrar una función que me ofrezca una predicción sobre cualquier cliente, para minimizar posibles pérdidas del banco, es
decir, busco $f:[0,1]^2 \rightarrow \{0,1\}$, que llamaremos predicción.

Asumimos que los datos de los clientes de que disponemos no van a tener una distribución determinada y
van a ser idéntica e independientemente distribuidos. El histórico siempre va a crecer, y no sabemos cómo va a hacerlo, queriendo aprovechar
al máximo la información del mismo. Es decir, los datos de un cliente provienen de una variable aleatoria que sigue una determinada
distribución $X \sim \mathcal{D}$; y tenemos muestas de clientes (que llamaremos conjunto de entrenamiento), variable i.i.d
$S \sim \mathcal{D}^m$. 

También asumiremos que tenemos una clase de predicciones $\mathcal{H} \subseteq \{0,1\}^{[0,1]^2}$, de entre las que existe
una óptima. Asumiremos por simplicidad que la clase de predicciones son subrectángulos de $[0,1]^2$, esto es, funciones:

\[h_{a,b,c,d} = \mathds{1}_{[a,b]\times[c,d]}, \qquad [a,b]\times [c,d] \subseteq [0,1]^2\]

\img{./imgs/rect-ex.png}{0.85}

También necesitaremos definir una medida de acierto: ¿cómo de buena es una predicción?.

\section{Modelo matemático}

Podemos dar unas notaciones/definiciones básicas que utilizaremos de aquí en adelante, en base a lo descrito en \ref{sec:first-ex}:

\begin{itemize}
\item \textbf{Dominio}: $\mathcal{X}$. Llamamos una instancia a $x\in \mathcal{X}$
\item \textbf{Conjunto de etiquetas}: $\mathcal{Y}$ consideramos $\{0,1\}$, lo que nos restringe al paradigma binario. En ocasiones 
también usaremos $\mathcal{Y} = \{-1,1\}$ para las etiquetas.
\item \textbf{Verdadero etiquetado}: \sloppy Asumimos la existencia de una función ${f: \mathcal{X} \rightarrow \mathcal{Y}}$ 
que devuelve el verdadero etiquetado de todas las instancias.
\item \textbf{Generación de instancias}: \fussy Asumimos la existencia de una distribución de probabilidad $\mathcal{D} = (\mathcal{B}, P)$, 
con $x\sim \mathcal{D}$, donde $A\subseteq \mathcal{P}(\mathcal{X})$ es $\sigma$ álgebra de conjuntos sobre $\mathcal{X}$ y $P: \mathcal{B} \rightarrow [0,1]$
función de probabilidad. La distribución de probabilidad nos da información sobre la probabilidad de extraer cada posible instancia desde 
$x \in \mathcal{X}$. Por evitar conflictos, usualmente escribiremos $P$ como $P_{x\sim \mathcal{D}}$.

\item \textbf{Conjunto de entrenamiento}: $S = ((x_1,y_1) \ldots (x_m,y_m)) \in (\mathcal{X} \times \mathcal{Y})^m$ 
Nótese que llamarlo conjunto puede dar lugar a confusión, puesto que se trata de una tupla. Notaremos $S_x = (x_1, \ldots x_m)$

De momento asumiremos que las etiquetas del conjunto de entrenamiento se corresponden con el verdadero etiquetado: 
$y_i = f(x_i)$, por lo que no podemos tener dos instancias con etiquetas diferentes.

La elección de $S_x$ es idéntica e independientemente distribuida, esto es $x_i \sim \mathcal{D}$ para todo $i=1, \ldots, m$.
Lo notamos $S_x \sim \mathcal{D}^m$

\item \textbf{Hipótesis/clasificador/predicción}: cada posible aplicación perteneciente a 
$\{h: h:\mathcal{X} \rightarrow \mathcal{Y}\} := 2^{\mathcal{X}}$. 

\item \textbf{Algoritmo de aprendizaje}: Llamamos algoritmo de aprendizaje a cualquier aplicación que tome conjuntos de entrenamiento
y devuelva hipótesis sobre el problema:

\[A: \underset{m\in \mathbb{N}}{\bigcup} (\mathcal{X}\times\mathcal{Y})^m \rightarrow 2^{\mathcal{X}}\]

Asumimos que el algoritmo no tiene acceso a la función de verdadero etiquetado $f: \mathcal{X} \rightarrow \mathcal{Y}$ ni a
la distribución $\mathcal{D}$.

\item \textbf{Error del clasificador}: Definimos el error del clasificador, suponiendo 
$\{x\in \mathcal{X} : h(x) \neq f(x)\} := [h\neq f] \in \mathcal{B}$ como:

\[L_{D,f}(h) :=  P_{x\sim \mathcal{D}} [h \neq f]\]
\end{itemize}


\begin{enumerate}
\item Minimización del riesgo empírico (ERM)
\label{sec-3-4-1-1}

\begin{definition}
\textbf{Riesgo empírico (ER)}

Definimos el riesgo empírico o error empírico como:

\[L_S(h) = \frac{|i\in {1\ldots m}: h(x_i) \neq y_i|}{m}\]
\end{definition}

Podemos pensar en él como el error del clasificador sobre el conjunto de entrenamiento. El paradigma que intenta buscar una hipótesis que minimice el error empírico recibe el nombre de \emph{Minimización de Riesgo Empírico - ERM} y notamos $ERM(S)$ al clasificador que obtenemos basándonos en este paradigma para un determinado conjunto de entrenamiento $S$.

Este error no es siempre óptimo. Pensemos en el siguiente ejemplo:

Sea $\mathcal{X} = \mathbb{R}$, $\mathcal{D}$ la distribución uniforme sobre $[0,2]\subset \mathbb{R}$, y la siguiente función:

\[f(x) = \left\{\begin{array}{lcl}
1 && x\in [0,1]\\
0 && x\in \mathbb{R}\setminus [0,1]
\end{array}\right.\]


$S = \{(x_1,y_1), \ldots (x_m, y_m)\}$ un conjunto de entrenamiento de tamaño $m$ sin elementos repetidos y el clasificador:

\[h_S(x) = \left\{\begin{array}{lcl}
y_i && \exists i\in \{1\ldots m\} : x=x_i\\
0 && \nexists i\in \{1\ldots m\} : x=x_i
\end{array}\right.\]

Este clasificador es perfecto respecto a la minimización de riesgo empírico, pero $\mathbb{P}_{x\sim \mathcal{D}}[h_S(x)] = 1/2$, es decir, tiene el mismo nivel de acierto que el clasificador idénticamente 1. A este fenómeno lo denominamos \textbf{overfitting}.

\item ERM con \emph{sesgo inductivo}
\label{sec-3-4-1-2}

Se intenta corregir el ERM corrigiendo el espacio de búsqueda, esto es, la clase de hipótesis $\mathcal{H}$ desde la que el algoritmo puede escoger un $h: \mathcal{X}\rightarrow \mathcal{Y}$. Llamamos a esto \emph{sesgo inductivo} puesto que se asumirá una determinada clase de funciones $\mathcal{H}$ en función de las características del problema.

Notaremos a este nuevo paradigma $ERM_{\mathcal{H}}(S)$, y lo definimos de manera que:

\[ERM_{\mathcal{H}}(S) := h_S \in argmin_{h\in \mathcal{H}} L_S(h)\]

Definimos la propiedad de factibilidad, que usaremos más adelante.

\begin{definition}
\textbf{Propiedad de factibilidad}

Existe  $\bar{h} \in \mathcal{H}$ verificando $L_{D,f}(\bar{h}) = 0$.
\end{definition}

La hipótesis de factibilidad implica que $\mathbb{P}_{S\sim \mathcal{D}^m}[L_S(\bar{h})=0] = 1$, y por tanto $\mathbb{P}_{S\sim \mathcal{D}^m}[L_S(h_S)=0]=1$.

El valor $L_{\mathcal{D},f}(h_S)$ dependerá del conjunto de entrenamiento $S$, y la elección del mismo está sometida al azar. Además, necesitamos definir cómo de buena será la predicción.
\end{enumerate}