\label{ch:sdisjuncts}
En este capítulo proporcionamos una sencilla experimentación de los algoritmos implementados, aplicándolos al concepto de 
\textit{small disjuncts} que se mencionó en \ref{sec:desbalanceo}, problema que surge como consecuencia del desbalanceo
intra clases.

\section{Marco de experimentación}
Se estudiarán los algoritmos MWMOTE, RWO, PDFOS sobre todos los datasets incluidos en el paquete \texttt{imbalance}. 
También se aplicará el algoritmo wRACOG sobre el único dataset de los del paquete enteramente discreto: \texttt{wisconsin},
puesto que en el resto de casos, con atributos continuos, no tendría sentido aplicar el algoritmo. También se hará una 
segunda experimentación, añadiendo filtrado con NEATER a cada uno de los algoritmos y datasets a los que pueden aplicarse.

Trabajaremos con la implementación de árboles C4.5 de \citepalias{rweka}: \texttt{J48}, usando árboles sin poda 
(opción \texttt{-U}), y sin mínimo de ejemplos por hoja (opción \texttt{-M=1}). 
Definiremos un \textit{small disjunct} como una hoja del árbol con 3 o menos ejemplos. Nótese 
que no hay definición formal para el concepto, pues este se define como reglas que cubren pocos ejemplos. Calcularemos para 
cada dataset el número de \textit{small disjuncts} (de ambas clases, puesto que se explicó en \ref{sec:desbalanceo} que 
es un problema que puede afectar a ambas clases), así como la media del número de ejemplos que cubren las hojas del árbol.
Si alguno de los algoritmos de \textit{oversampling} introdujera más \textit{small disjuncts} en lugar de eliminarlos, 
la media de cobertura de las hojas bajaría, y el número de \textit{small disjuncts} crecería. Por tanto teorizamos que si eliminamos 
desbalanceo en los datasets, el número de \textit{small disjuncts} decrecerá, y la media de ejemplos por hoja aumentará.

Se dividirá cada conjunto en 3 particiones estratificadas por clase (esto es, la proporción de ejemplos de ambas
clases será aproximadamente igual que en el conjunto sin particionar), y se intentará conseguir un ratio de desbalanceo del
80\% con cada uno de los algoritmos. Se hará una media de las medidas descritas para cada dataset, y compararemos los 
resultados con los obtenidos para las 3 particiones sin ningún algoritmo aplicado.

La experimentación es completamente reproducible, y se encuentra disponible en la carpeta \texttt{experimentacion} del 
repositorio que aloja al presente trabajo \footnote{\url{https://github.com/ncordon/tfg}}.
Ahí pueden encontrarse dos archivos: \texttt{aux.R} y \texttt{small-disjuncts.R}. Basta ejecutar el segundo archivo
para reproducir la experimentación.

\section{Contenido de \texttt{aux.R}}
\texttt{RWeka} no proporciona ningún método para obtener la cobertura de las hojas de los árboles que construye, así que
ha sido necesario un método para \textit{parsear} la impresión que se hace del árbol en forma de cadena de caracteres

\lstinputlisting[caption=función \texttt{leavesCoverage} en \texttt{aux.R}]{./codelst/leavesCoverage.R}

Asimismo, en dicho archivo también podemos encontrar las funciones \texttt{makePartition}, que recibe un \texttt{dataset}
y un número de particiones \texttt{numPartitions} y genera \texttt{numPartitions} estratificadas a partir del dataset; la
función \texttt{infoSmallDisjuncts} que recibe un \texttt{dataset} y devuelve el cálculo de las dos medidas descritas, y 
la función \texttt{getResults}, que recibe un parámetro \textit{booleano} indicando si queremos aplicar el filtro NEATER
o no.
\clearpage
\lstinputlisting[caption=función \texttt{infoSmallDisjuncts} en \texttt{aux.R}]{./codelst/infoSmallDisjuncts.R}

\section{Contenido de \texttt{small-disjuncts.R}}
Este archivo es el fichero principal de la experimentación. Comienza fijando una semilla aleatoria de modo que la experimentación
sea reproducible, carga librerías, el fichero auxiliar \texttt{aux.R}, los datos de \texttt{imbalance}, los particiona,
crea un \textit{wrapper} para \texttt{wRACOG} basado en \texttt{J48} y obtiene los resultados de la experimentación.

\section{Resultados}
En los resultados, \texttt{none} representa el dataset original sin tratamiento de \textit{oversampling}. En la columna
correspondiente al algoritmo PDFOS faltan algunos datos debido a que las matrices de los datos particionados resultan
no invertibles. La columna de wRACOG sólo incluye el único dataset discreto, \texttt{wisconsin}.
\subsection{Sin filtrado de instancias}
  \begin{table}[H]
  \centering
  \begin{tabular}{rrrrrr}
   \hline
   & none & mwmote & wracog & rwo & pdfos \\ 
   \hline
   ecoli1 & 24.83 & 20.39 &  & 14.13 &  \\ 
   glass0 & 13.30 & 8.76 &  & 11.07 &  \\ 
   haberman & 45.05 & 14.86 &  & 20.00 & 22.31 \\ 
   iris0 & 25.00 & 30.33 &  & 30.33 & 30.33 \\ 
   newthyroid1 & 19.89 & 30.00 &  & 20.40 & 23.40 \\ 
   wisconsin & 6.74 & 3.88 & 5.68 & 3.65 & 3.65 \\ 
   yeast4 & 77.83 & 30.69 &  & 55.21 &  \\ 
   \hline
  \end{tabular}
  \caption{Media de \textit{small disjuncts} tras \textit{oversampling}}
  \end{table}

  \begin{table}[H]
  \centering
  \begin{tabular}{rrrrrr}
   \hline
   & none & mwmote & wracog & rwo & pdfos \\ 
   \hline
   ecoli1 & 2.67 & 3.00 &  & 17.67 &  \\ 
   glass0 & 2.33 & 5.00 &  & 3.67 &  \\ 
   haberman & 1.33 & 6.33 &  & 3.33 & 4.33 \\ 
   iris0 & 0.00 & 0.00 &  & 0.00 & 0.00 \\ 
   newthyroid1 & 1.67 & 1.33 &  & 1.67 & 1.00 \\ 
   wisconsin & 27.67 & 62.33 & 36.00 & 65.67 & 65.67 \\ 
   yeast4 & 3.00 & 16.67 &  & 5.00 &  \\ 
   \hline
  \end{tabular}
  \caption{Tamaño medio de coberturas tras \textit{oversampling}}
  \end{table}
  
\subsection{Con filtrado de instancias}
  \begin{table}[H]
  \centering
  \begin{tabular}{rrrrrr}
   \hline
   & none & mwmote & wracog & rwo & pdfos \\ 
   \hline
   ecoli1 & 24.83 & 19.59 &  & 14.10 &  \\ 
   glass0 & 13.30 & 9.80 &  & 14.77 &  \\ 
   haberman & 45.05 & 9.37 &  & 14.32 & 12.55 \\ 
   iris0 & 25.00 & 30.33 &  & 30.33 & 30.33 \\ 
   newthyroid1 & 19.89 & 28.83 &  & 21.19 & 23.85 \\ 
   wisconsin & 6.74 & 3.88 & 5.78 & 3.67 & 3.71 \\ 
   yeast4 & 77.83 & 35.66 &  & 52.80 &  \\ 
   \hline
  \end{tabular}
  \caption{Media de \textit{small disjuncts} tras \textit{oversampling} y filtrado}
  \end{table}

  \begin{table}[H]
  \centering
  \begin{tabular}{rrrrrr}
   \hline
   & none & mwmote & wracog & rwo & pdfos \\ 
   \hline
   ecoli1 & 2.67 & 2.67 &  & 17.67 &  \\ 
   glass0 & 2.33 & 3.67 &  & 3.33 &  \\ 
   haberman & 1.33 & 7.33 &  & 3.00 & 5.33 \\ 
   iris0 & 0.00 & 0.00 &  & 0.00 & 0.00 \\ 
   newthyroid1 & 1.67 & 1.33 &  & 2.33 & 1.00 \\ 
   wisconsin & 27.67 & 62.33 & 34.33 & 65.00 & 63.67 \\ 
   yeast4 & 3.00 & 9.67 &  & 4.00 &  \\ 
   \hline
  \end{tabular}
  \caption{Tamaño medio de coberturas tras \textit{oversampling} y filtrado}
  \end{table}
  
  Se puede observar cómo nuestros algoritmos consiguen en muchos casos reducir el número de hojas de pequeña 
  cobertura existente en los datasets, y aumentar los tamaños medios de las mismas, aunque hemos usado en todos ellos
  los parámetros por defecto, y podrían obtenerse mejores resutlados si intentásemos optimizar los mismos. Además, la medida
  de \textit{small disjuncts} que está siendo empleada es bastante arbitraria, y podría intentarse encontrar una más
  adaptada a cada dataset: hojas que tuviesen una cobertura inferior al 80\% de la media, por ejemplo.
 