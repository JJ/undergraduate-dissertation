En este capítulo introducimos el espacio de probabilidad y el espacio de probabilidad producto. El teorema de
extensión de Caratheodory nos asegurará que siempre es posible definir dicho espacio de probabilidad producto.
También ofrecemos resultados fundamentales sobre medidas de concentración probabilísticas, que usaremos más
adelante.
\section{$\sigma$ álgebras, anillos y semianillos}
Sea en lo que sigue $X$ un conjunto. Dados $A_i \subseteq X$, para $i=1, \ldots n$, notamos $\sum_{i=1}^n A_i$
a su unión disjunta, esto es $\bigcup_{i=1}^n A_i$ con $A_i \cap A_j = \emptyset$ cuando $i\neq j$.

\begin{definition}[Conjunto potencia]
 Definimos el conjunto potencia de $X$ como $\mathcal{P}(X):= \{A: A\subseteq X\}$.
  
 Como notación para $\mathcal{P}(X)$ usaremos frecuentemente $2^X$.
\end{definition}

\begin{definition}[$\sigma$-álgebra]
 $\Sigma \subseteq 2^X$ es $\sigma$-álgebra de conjuntos sobre $X$ si se verifica:
 
 \begin{enumerate}[i]
  \item $X \in \Sigma$
  \item Es cerrada para complementarios: sea $A\in \Sigma$, entonces $A^c = X\setminus A \in \Sigma$
  \item $\Sigma$ es cerrada para uniones numerables: sean $\{A_n\}_{n\in\mathbb{N}} \subseteq \Sigma$, entonces: 
  \[
    \underset{n \ge 1}{\bigcup} A_n \in \Sigma
  \]
 \end{enumerate}
\end{definition}

\begin{fact}
 Sea $\Sigma$ $\sigma$-álgebra sobre $X$. Entonces:
 
 \begin{enumerate}[i]
  \item $\emptyset \in \Sigma$
  \item $\Sigma$ es cerrada para intersecciones: dados $A,B \in \Sigma$, entonces $A\cap B \in \Sigma$
  \item $\Sigma$ es cerrada para diferencias: dados $A,B \in \Sigma$, entonces $A\setminus B \in \Sigma$
 \end{enumerate}
 
 \label{fact:propsigma}
\end{fact}

  \begin{proof}
   Escribimos $\emptyset = X^c$, $A\cap B = (A^c \cup B^c)^c$ y $A\setminus B = A\cap B^c$
   y usando las hipótesis de $\sigma$-álgebra se deduce fácilmente la proposición.
  \end{proof}

\begin{definition}
 Sea $\mathcal{A} \subseteq 2^X$. Llamamos $\sigma$-álgebra generada por $\mathcal{A}$ y lo notamos 
 $\Sigma(\mathcal{A})$, a la menor $\sigma$-álgebra sobre $X$ que contiene a $\mathcal{A}$.
 \[
   \Sigma(\mathcal{A}) = 
   \bigcap_{\begin{array}{c}\Sigma, \sigma\textrm{-álgebra en } X\\ \mathcal{A}\subseteq \Sigma \end{array}} \Sigma
 \]
\end{definition}

\begin{definition}[Semianillo en $X$]

 $S\subseteq 2^X$ es semianillo si verifica:
 
 \begin{enumerate}[i]
  \item $\emptyset \in S$
  \item $A,B \in S$ entonces $A\cap B \in S$
  \item $A,B \in S$ entonces existen $A_1 \ldots A_n \in S$ verificándose $A\setminus B = \sum_{i=1}^n A_i$
 \end{enumerate}
\end{definition}

Damos un ejemplo de semianillo:

\begin{example}
 \label{ex:rectangulos}
 \begin{definition*}
  Sean $X_1, X_2$ conjuntos, $\Sigma_i$ $\sigma$-álgebra sobre $X_i$. 
  
  Dados $A_1 \in \Sigma_1, A_2 \in \Sigma_2$ arbitrarios, definimos el rectángulo de lados $A_1$ y $A_2$ como:
  \[
    Rec(A_1, A_2) = A_1 \times A_2
  \]
 \end{definition*}
 
 
 La clase de rectángulos $Rec = \{Rec(A_1, A_2): A_i \in \Sigma_i\}$ es un semianillo en $X_1 \times X_2$,
 ya que dados $R_1 = A_1 \times A_2 \in Rec, R_2 = B_1 \times B_2 \in Rec$ arbitrarios:
 
 \begin{enumerate}
  \item $\emptyset \in \Sigma_i$, y $\emptyset \times \emptyset = \emptyset$
  \item $R_1 \cap R_2 = (A_1 \cap B_1) \times (A_2 \cap B_2)$, donde $A_i \cap B_i \in \Sigma_i$ por ser 
  $\Sigma_i$ cerrada bajo intersecciones.
  \item $R_1 \setminus R_2 = \{(x,y): (x,y) \in A_1 \times A_2, (x,y) \notin B_1 \times B_2)\}$
  
  Es decir $R_1 \setminus R_2 = Rec(A_1\setminus B_1, A_2) \cup Rec(B_1, A_2\setminus B_2)$. Además
  $A_i \setminus B_i \in \Sigma_i$ por ser $\Sigma_i$ cerrada bajo diferencias.
 \end{enumerate}

\end{example}


\begin{definition}[Anillo en $X$]
 $R\subseteq 2^X$ es anillo si verifica:
 
 \begin{enumerate}[i]
  \item $\emptyset \in R$
  \item $A,B \in R$ entonces $A\cup B \in R$
  \item $A,B \in R$ entonces $A\setminus B \in R$
 \end{enumerate}
\end{definition}


\begin{fact}
 Toda $\sigma$-álgebra es anillo. Todo anillo es semianillo.
\end{fact}

  \begin{proof}
   Que $\sigma$-álgebra es más fuerte que anillo quedó probado en la proposición \ref{fact:propsigma}.
   
   Sea ahora $R \subseteq X$ anillo y veamos que es semianillo.

   Como $A\cap B = A\setminus (A\setminus B)$, se deduce la segunda condición de la definición de semianillo.
   
   Sean $A, B \in R$, tomando $A_1 = A\setminus B \in R$, $A_n = \emptyset \in R$ para todo $n > 1$, entonces se 
   verifica la tercera condición de semianillo.
  \end{proof}

\begin{counterex}
 Veamos un contraejemplo de que no todo semianillo es anillo:
 
 $\Sigma = \{\emptyset, [0,1], [1,2], [0,2]\}$ es $\sigma$-álgebra sobre $[0,2]$, y $[0,1]^2$ y $[1,2]^2$ son rectángulos
 en $[0,2]^2$, pero $[0,1]^2 \cup [1,2]^2$ no puede ser escrito como producto de $A,B \in \Sigma$.
 
 Y uno de que no todo anillo es $\sigma$-álgebra:
 
 Sea $S = \{A\subseteq \mathbb{N}: |A| < \infty\}$. Entonces se puede comprobar fácilmente que es anillo (y semianillo)
 de $\mathbb{N}$, pero no es cerrado para complementarios porque $\mathbb{N} = \emptyset^c$ no es finito.
\end{counterex}


\begin{definition}
 Sea $\mathcal{A} \subseteq 2^X$. Llamamos anillo generado por $\mathcal{A}$ y lo notamos $(\mathcal{A})$ al
 menor anillo que contiene a $\mathcal{A}$:
 \[
   (\mathcal{A}) = \bigcap_{\begin{array}{c}R \textrm{ anillo en } X\\ \mathcal{A}\subseteq R \end{array}} R
 \]
\end{definition}

Es trivial probar que la definición es correcta ($(\mathcal{A})$ es anillo), ya que dados dos 
conjuntos $B,C \in (\mathcal{A})$, entonces $A, B \in R$ para todo $R$ anillo conteniendo a $A$. Además la
intersección es no vacía, porque $2^X \supseteq \mathcal{A}$ y $2^X$ es anillo.

\begin{fact}
 Sea $S$ un semianillo en $X$. Entonces:
 \[
   (S) = \left\{\sum_{i=1}^n A_i:  n\ge 1, A_i \in S\right\}
 \]
 \label{claim:semiring}
\end{fact}

  \begin{proof}
   Sea $R= \left\{\sum_{i=1}^n A_i:  n\ge 1, A_i \in S\right\}$. Es claro que $S\subseteq R$.
   
   Sean $A = \sum_{i=1}^n A_i, B = \sum_{j=1}^p B_j \in R$ no nulos. Entonces 
   $A\cap B = \sum_{i,j} (A_i \cap B_j)\in R$, por ser $A_i\cap B_j \in S$. Por tanto $R$ es cerrado para intersección de 
   elementos. Además:
    \[
      A\setminus B = \cup_{i=1}^n A_i \bigcap \cap_{j=1}^p B_j^c = \bigcap_{j=1}^p 
                     \left(\sum_{i=1}^n (A_i \cap B_j^c)\right) = 
                     \bigcap_{j=1}^p \left(\sum_{i=1}^n \sum_{k=1}^{k(i,j)} C_{ij,k(i,j)} \right)
    \]
   donde se ha aplicado que si $A_i, B_j \in S$ existen $C_{ij,1}, \ldots, C_{ij,k(i,j)} \in S$ verificando
   $A\setminus B_j =\sum_{k=1}^{k(i,j)} C_{ij,k(i,j)}$. Luego aplicando que $R$ es cerrado para intersecciones, 
   llegamos también a que lo es para diferencias.
   
   Por último, como $A\cup B = A \setminus B + B$, entonces $A \cup B \in R$, y $R$ es anillo, con $(S) \subseteq R$.
   Por otro lado, $(S)$ debe contener por definición de anillo las uniones de elementos de $S$, en particular
   $R\subseteq (S)$. Luego $(S) = R$.
  \end{proof}


\begin{fact}
 Sea $S$ un semianillo en $X$. Entonces:
 \[
   \Sigma(S) = \Sigma((S))
 \]
\end{fact}

  \begin{proof}
   $S\subseteq (S)$, luego $\Sigma(S) \subseteq \Sigma((S))$
   
   Por otro lado, $\sum_{i=1}^n A_i \in \Sigma(S)$ para $A_i \in S$, luego $(S) \subseteq \Sigma(S)$, y por tanto
   deducimos $\Sigma((S)) \subseteq \Sigma(S)$.
  \end{proof}
  

\section{Medidas y extensión de medidas}

\begin{definition}[Medida]
 Sea $\mathcal{A} \subseteq 2^X$. Llamamos medida sobre $\mathcal{A}$ a cualquier función 
 $\mu: \mathcal{A} \rightarrow [0, +\infty]$ verificando:

 \begin{enumerate}[i]
  \item $\mu(\emptyset) = 0$
  \item $\mu$ es $\sigma$-aditiva: dados $A_n \in \mathcal{A}$ disjuntos tales que $\sum_{i=1}^n A_i \in \mathcal{A}$, 
  entonces 
  \[
    \mu\left(\sum_{i=n}^{+\infty} A_n \right)= \sum_{i=n}^{+\infty} \mu(A_n)
  \]
 \end{enumerate}
\end{definition}

Nótese que la $\sigma$-aditividad implica aditividad finita, esto es, dados $A_i \in \mathcal{A}, i=1, \ldots, n$,
disjuntos, tales que $\sum_{i=1}^n A_i \in \mathcal{A}$, entonces $\mu\left(\sum_{i=1}^{n} A_i \right)= \sum_{i=1}^{n} \mu(A_i)$.

\begin{theorem}
 Sea $S$ semianillo en $X$, $\mu: S \rightarrow [0,+\infty]$ medida sobre $S$. Entonces existe una única medida 
 sobre $(S)$, $\bar{\mu}: (S) \rightarrow [0,+\infty]$ verificando $\bar{\mu}_{|S} = \mu$.
 
 \label{th:ext-semitoring}
\end{theorem}

  \begin{proof}
   Recordamos que $(S) = \left\{\sum_{i=1}^n A_i: n\ge 1, A_i \in S \right\}$ por la proposición \ref{claim:semiring}.
   
   Es claro que $\bar{\mu}$ debería cumplir: 
   $\bar{\mu}\left(\sum_{i=1}^n A_i\right) = \sum_{i=1}^n \bar{\mu}(A_i) = \sum_{i=1}^n \mu(A_i)$
   con $A_i \in S$. Por tanto, dado $A\in (S)$, tomamos $A_i\in S$ verificando $A = \sum_{i=1}^n A_i$, y definimos: 
   \[
     \bar{\mu}(A) := \sum_{i=1}^n \mu(A_i)
   \]
   
   Veamos que $\bar{\mu}$ está bien definida, esto es, dado $\sum_{i=1}^n A_i = \sum_{j=1}^k B_j = A$, 
   veamos que se verifica $\sum_{i=1}^n \mu(A_i) = \sum_{j=1}^k \mu(B_j)$.
   Como $A_i = A_i \cap A = A_i \cap \left(\cup_{j=1}^k B_j\right) = \bigcup_{j=1}^k A_i \cap B_j$, donde 
   $A_i \cap B_j \in S$ por ser $S$ semianillo. Además como los $A_i$ son disjuntos, los $A_i\cap B_j$ también.
   Aplicando que $\mu$ es medida sobre $S$:
   \[
     \mu(A_i) = \sum_{j=1}^k \mu(A_i \cap B_j) \implies \sum_{i=1}^n \mu(A_i) = 
                \sum_{i=1}^n \sum_{j=1}^k \mu(A_i \cap B_j)
   \]
   
   Análogamente podemos probar:
   \[
     \sum_{j=1}^k \mu(B_j) = \sum_{i=1}^n \sum_{j=1}^k \mu(A_i \cap B_j)
   \]
   
   Luego $\bar{\mu}$ está bien definida. Además $\bar{\mu} (\emptyset) = 0$ por ser $\mu(\emptyset) = 0$.
   Falta probar la $\sigma$-aditividad de $\bar{\mu}$ y por construcción, habríamos llegado al resultado buscado.
   
   Sean $A_n = \sum_{i=1}^{k_n} A_i^n \in (S)$ disjuntos tal que $A_i^n \in S$ y $A = \sum_{n=1}^{+\infty} A_n \in (S)$. 
   Por ser $A \in (S)$, tendríamos que podemos reescribir $A = \sum_{j=1}^k B_j$ con $B_j \in S$.
   Fijamos un $B_p$ y tenemos:
   \[
     B_p = A \cap B_p = \bigcup_{n=1}^{+\infty} \left(\bigcup_{i=1}^{k_n} A_i^n \cap B_p\right) = 
             \bigcup_{n=1}^{+\infty} \bigcup_{i=1}^{k_n} \left(A_i^n \cap B_p\right)
   \]
   Es decir, hemos reescrito $B_p$ como una unión numerable disjunta de $A_i^n \cap B_p \in S$.
   
   Por $\sigma$-aditividad en $S$ deducimos $\mu(B_p) = \sum_{n=1}^{+\infty} \sum_{i=1}^{k_n} \mu(A_i^n \cap B_p)$.
   Además, como podemos reescribir $A_i^{n} = \sum_{j=1}^k A_i^{n} \cap B_j$, tendríamos:
   \begin{align*}
   \mu(A) &= \sum_{j=1}^k \sum_{n=1}^{+\infty} \sum_{i=1}^{k_n} \mu(A_i^n \cap B_j) =
             \sum_{n=1}^{+\infty} \sum_{i=1}^{k_n} \sum_{j=1}^k \mu(A_i^n \cap B_j)\\
          &= \sum_{n=1}^{+\infty} \sum_{i=1}^{k_n} \mu(A_i^n) =
             \sum_{n=1}^{+\infty} \mu \left(\sum_{i=1}^{k_n} A_i^n \right) =
             \sum_{n=1}^{+\infty} \mu(A_n)
   \end{align*}
  \end{proof}

\begin{definition}[Medida exterior]
 Sea $\mu^\ast : 2^X \rightarrow [0, +\infty]$ verificando:
 
 \begin{enumerate}[i]
  \item $\mu^\ast(\emptyset) = 0$
  \item Monotonía: $A\subseteq B$ entonces $\mu^\ast(A) \le \mu^\ast(B)$
  \item $\sigma$-subaditividad: $\mu^\ast \left(\bigcup_{n=1}^{+\infty} A_n \right) \le \sum_{n=1}^{+\infty} \mu^\ast (A_n)$
 \end{enumerate}
 
 Entonces $\mu^\ast$ se dice medida exterior sobre $X$.
\end{definition}

\begin{definition}
 Sea $\mu^\ast$ una medida exterior sobre $X$. Se define la $\sigma$-álgebra asociada a $\mu^\ast$ como:
 \[
   \Sigma(\mu^\ast) = \{A\subseteq X: \mu^\ast(T) = \mu^\ast(T\cap A) + \mu^\ast(T\cap A^c), \forall T\subseteq X\}
 \]
\end{definition}

Queda comprobar $\Sigma(\mu^\ast)$ es efectivamente una $\sigma$-álgebra.

\begin{theorem}
 Sea $\mu^\ast : 2^X \rightarrow [0, +\infty]$ una medida exterior sobre $X$. Entonces $\Sigma(\mu^\ast)$
 es una $\sigma$-álgebra sobre $X$ y $\mu^\ast_{|\Sigma(\mu^\ast)}$ es una medida sobre $\Sigma(\mu^\ast)$
 \label{th:outer-to-measure}
\end{theorem}

  \begin{proof}
   Empezamos viendo que $\Sigma = \Sigma(\mu^\ast)$ es una $\sigma$-álgebra.
   \[
     \mu^\ast(T) = \mu^\ast(T\cap X) + \mu^\ast(T\cap \emptyset) = \mu^\ast(T), \quad \forall T\subseteq X
   \]
   Luego $X,\emptyset \in \Sigma$. También es trivial ver que dado $A\in \Sigma$, entonces $A^c \in \Sigma$.
   
   Veamos que $\Sigma$ es cerrada para intersecciones. Sean $A, B\in \Sigma$. Usaremos:
   \begin{align}
    & T\cap A^c = T\cap (A\cap B)^c \cap A^c \nonumber\\
    & T\cap A \cap B^c = T \cap (A\cap B)^c \cap A
    \label{eqn:set-eqs}\tag{$\ast$}
   \end{align}
   Como $A\in \Sigma$, tenemos $\mu^\ast(T) = \mu^\ast(T\cap A) + \mu^\ast(T\cap A^c)$. 
   Por otro lado, como $B\in \Sigma$, tenemos $\mu^\ast(T\cap A) = \mu^\ast(T\cap A\cap B) + \mu^\ast(T\cap A \cap B^c)$. 
   Es decir:
   \begin{align*}
    \mu^\ast(T) &= \mu^\ast(T\cap A^c) + \mu^\ast(T\cap A \cap B) + \mu^\ast(T\cap A \cap B^c)\\
    & \underset{\eqref{eqn:set-eqs}}{=} \mu^\ast(T\cap (A\cap B)^c \cap A^c) + \mu^\ast(T \cap (A\cap B)^c \cap A)\\
    &+ \mu^\ast(T\cap A \cap B) = \mu^\ast(T\cap (A \cap B)^c) + \mu^\ast(T\cap A \cap B)
   \end{align*}
   donde en la última igualdad se ha usado que $A\in \Sigma$.
   
   Como podemos escribir $A\setminus B = A\cap B^c$, y $A\cup B = (A^c \cap B^c)^c$ con $A, B \in \Sigma$ que
   hemos probado que es cerrado para intersecciones y complementarios, $\Sigma$ es también cerrado para
   uniones y diferencias.
   
   Dados $A_n \in \Sigma$, como podemos escribir $\bigcup_{n\ge 1} A_n = \sum_{n=1}^{+\infty} B_n$ con los $B_n$ 
   disjuntos, definidos como $B_1 = A_1$, y $B_{n+1} = A_{n+1} \setminus\left(\cup_{i=1}^n A_i\right)$, 
   podemos limitarnos a estudiar uniones disjuntas.
   
   De hecho, dados $B,C \in \Sigma$ disjuntos:
   \begin{align*}
    \mu^\ast(T \cap (B\cup C)) &= \mu^\ast(T \cap(B\cup C) \cap B) + \mu^\ast(T \cap(B\cup C) \cap B^c)\\
                               &= \mu^\ast(T \cap B) + \mu^\ast(T \cap C)
   \end{align*}
   Sean $B_n$ conjuntos disjuntos de $\Sigma$, y llamamos $B = \sum_{n=1}^{+\infty} B_n$, $\bar{B}_k = \sum_{n=1}^{k} B_n$.
   Hemos visto que $\Sigma$ es cerrada para uniones finitas, luego $\bar{B}_k \in \Sigma$ para todo $k\in \mathbb{N}$.
   Vamos a ver que también lo es para uniones numerables. Sea $T\in 2^X$.

   Si $\mu^\ast(T) = +\infty$, entonces $\mu^\ast(T) \le \mu^\ast(T\cap B ) + \mu^\ast(T\cap B^c) = +\infty$, usando 
   monotonía. Se da la igualdad.
   
   Si $\mu^\ast(T) < +\infty$, tenemos $\mu^\ast(T) \ge \mu^\ast(T\cap \bar{B}_k) = \sum_{n=1}^k \mu^\ast(T\cap B_n)$
   para $k$ arbitrario, y por tanto $\mu^\ast(T) \ge \sum_{n=1}^{+\infty} \mu^\ast(T\cap B_n)$. Fijado $\varepsilon > 0$
   existe $M\in \mathbb{N}$ verificando que para todo $N\ge M$:
   \[
     \sum_{n=1}^{+\infty} \mu^\ast(T\cap B_n) \le \sum_{n=1}^N \mu^\ast(T\cap B_n) + \varepsilon = 
     \mu^\ast(T\cap \bar{B}_N) + \varepsilon
   \]
   
   Es decir, tendríamos:
   \begin{align*}
    \mu^\ast(T) &=   \mu^\ast(T\cap B^c + T\cap B) \le \mu^\ast(T\cap B^c) + \mu^\ast(T\cap B)\\
                &\le \mu^\ast(T\cap B^c) + \sum_{n=1}^{+\infty}\mu^\ast(T\cap B_n)\\
                &\le \mu^\ast(T\cap \bar{B}_N^c) + \mu^\ast(T\cap \bar{B}_N) + \varepsilon
                  =  \mu^\ast(T) + \varepsilon
   \end{align*}
   
   Pero $\varepsilon > 0$ era arbitrario, luego $\mu^\ast(T) = \mu^\ast(T\cap B^c) + \mu^\ast(T\cap B)$ y tomando 
   $T=B$, se deduce también que $\mu^\ast(B) = \sum_{n=1}^{+\infty}\mu^\ast(B_n)$.
   
   Es decir, $\Sigma$ es $\sigma$-álgebra. y $\mu|_{\Sigma}$ es medida sobre $\Sigma$.
  \end{proof}


\begin{theorem}[Teorema de extensión de Caratheodory]
 Sea $S \subseteq 2^X$ un semianillo, $\mu:S \rightarrow [0,+\infty]$ medida en $S$. Entonces existe
 una medida $\bar{\mu}:\Sigma(S) \rightarrow [0,+\infty]$ verificando $\bar{\mu}_{|S} = \mu$
 \label{th:caratheodory}
\end{theorem}

  \begin{proof}
   Si existiese $\bar{\mu}$ debería verificar, por monotonía, $\bar{\mu}(T) \le \sum_{n=1}^{+\infty} \bar{\mu}(A_n)$, 
   donde $T \subseteq \bigcup_{n\ge 1} A_n$. Esto nos da una idea de la prueba.
   
   Por el teorema \ref{th:ext-semitoring}, podemos considerar $\mu$ como la extensión al anillo $R=(S)$.
   
   Definimos, para cualquier $T\in 2^X$:
   \[
     \mu^\ast(T):= \inf\left\{\sum_{n=1}^{+\infty} \mu(A_n): \bigcup_{n\ge 1} A_n \supseteq T,
                   A_n\in R \quad \forall n\in\mathbb{N}\right\}
   \]
   donde por convención adoptamos $\inf \emptyset := +\infty$.
   Además, como $\mu \ge 0$, entonces $\mu^\ast \ge 0$, y como $\mu^\ast(\emptyset) = 0$, entonces $\mu(\emptyset) = 0$.
   Vamos a ver que $\mu^\ast$ es medida exterior sobre $X$.
    
   Dado $B\subseteq A \subseteq X$, tenemos que si $\bigcup_{n\ge 1} A_n \supseteq A$ con $A_n\in R$
   entonces $\bigcup_{n\ge 1} A_n \supseteq B$ y de la definición de $\mu^\ast$ deducimos $\mu^\ast(A) \le \mu^\ast(B)$.
   Hemos probado la monotonía de $\mu^\ast$.
   
   Sean ahora $A_n \subseteq X$, con $n\in \mathbb{N}$.Si existe $A_k$ tal que $\mu^\ast(A_k) = +\infty$, entonces 
   $\mu^\ast\left(\bigcup_{n\ge 1} A_n\right) \ge \mu^\ast(A_k) = +\infty$, 
   por monotonía, y por otro lado $\sum_{n=1}^{+\infty} \mu^\ast(A_n) \ge \mu^\ast(A_k) = +\infty$. Es decir:
   \[\mu^\ast\left(\bigcup_{n\ge 1} A_n\right) = \sum_{n=1}^{+\infty} \mu^\ast(A_n) = +\infty\]
   
   Caso de que para todo $n$ se tenga $\mu^\ast(A_n) < +\infty$, fijamos $\varepsilon > 0$.
   Dado $n\in \mathbb{N}$, por ser $\mu^\ast(A_n)$ un ínfimo, debe existir $\{A_p^n\}_{p\ge 1}\subseteq R$
   verificando $\cup_{p\ge 1} A_p^n \supseteq A_n$ y $\sum_{p=1}^{+\infty} \mu^\ast(A_p^n) \le \mu^\ast(A_n) + \frac{\varepsilon}{2^n}$.
   
   Así, tenemos $\bigcup_{n\ge 1} A_n \subseteq \bigcup_{n\ge 1} \cup_{p\ge 1} A_p^n$ unión numerable
   de conjuntos $A_p^n$ de $S$, luego:
   \[
     \mu^\ast \left(\bigcup_{n\ge 1} A_n \right) \le \sum_{n=1}^{+\infty} \sum_{p=1}^{+\infty} \mu^\ast(A_p^n)
     \le \sum_{n=1}^{+\infty}\mu^\ast(A_n) + \sum_{n=1}^{+\infty}\frac{\varepsilon}{2^n} = 
     \sum_{n=1}^{+\infty}\mu^\ast(A_n) + \varepsilon
   \]
   
   Pero como $\varepsilon > 0$ era arbitrario: 
   \[
     \mu^\ast \left(\bigcup_{n\ge 1} A_n \right) \le \sum_{n=1}^{+\infty}\mu^\ast(A_n)
   \]
   
   Esto prueba la subaditividad, por lo que $\mu^\ast$ es medida exterior en $X$, y podemos tomar $\widetilde{\mu}$ medida 
   sobre $\Sigma(\mu^\ast)$ por el teorema \ref{th:outer-to-measure}. Falta comprobar que $\bar{\mu} = \widetilde{\mu}_{|\Sigma(S)}$ es medida sobre $\Sigma(S)$. Basta ver que 
   $S\subseteq \Sigma(\mu^\ast)$, y tendríamos $\Sigma(S) \subseteq \Sigma(\mu^\ast)$.
   
   Fijamos $A\in R$. Se cumple que para todo $T\in 2^X$ arbitrario, por subaditividad:
   \[
     \mu^\ast(T) \le \mu^\ast(T\cap A) + \mu^\ast(T\cap A^c)
   \]
   
   Sea ahora $T_n \in R$ con $T\subseteq \bigcup_{n\ge 1} T_n$. Entonces 
   $T\cap A \subseteq \bigcup_{n\ge 1} T_n \cap A$ y $T\cap A \subseteq \bigcup_{n\ge 1} T_n \cap A^c$ con 
   $A\cap T_n, A^c \cap T_n \in R$. Nótese que aquí estamos usando explícitamente que $R$ es anillo. Así:
   \begin{align*}
   \mu^\ast(T) &\le \mu^\ast(T\cap A) + \mu^\ast(T\cap A^c)\\ 
               &\le \sum_{n=1}^{+\infty}\mu(T_n \cap A) + \sum_{n=1}^{+\infty} \mu(T_n \cap A^c)\\
               &= \sum_{n=1}^{+\infty}\mu(T_n \cap A) + \mu(T_n \cap A^c) = \sum_{n=1}^{+\infty} \mu(T_n)  
   \end{align*}
   
   Fijado $\varepsilon > 0$ podemos buscar $T_n \in R$ verificando $\sum_{n=1}^{+\infty} \mu(T_n) \le \mu^\ast(T) + \varepsilon$, 
   por estar definido $\mu^\ast$ como un ínfimo. Por ser $\varepsilon > 0$ arbitrario, hemos llegado a: 
   \[
     \mu^\ast(T) = \mu^\ast(T\cap A) + \mu^\ast(T\cap A^c) \Rightarrow A\in \Sigma(\mu^\ast)
   \]
  \end{proof}



\section{Espacio probabilístico}
\label{sec:prob-space}
\begin{definition}[Espacio medible]
 Sea $X$ un conjunto, $\Sigma$ una $\sigma$-álgebra sobre $X$. A la tupla $(X,\Sigma)$ la llamamos
 espacio medible. A los elementos de $\Sigma$ los llamamos conjuntos $\Sigma$-medibles.
\end{definition}


\begin{definition}[Espacio de medida]
 Sea $(X, \Sigma)$ espacio medible, y $\mu: \Sigma \rightarrow [0,+\infty]$ medida. A la tupla $(X, \Sigma, \mu)$ 
 la llamamos espacio de medida.
\end{definition}


\begin{definition}[Espacio de probabilidad]
 Sea $(X, \Sigma, P)$ espacio de medida. Entonces lo llamamos espacio de probabilidad sii $P(\Sigma)\subseteq [0,1]$.
\end{definition}


\begin{definition}[Distribución de probabilidad]
 Sea $(X, \Sigma, P)$ espacio de probabilidad. Llamamos a la tupla $\dist = (\Sigma,P)$ distribución sobre $X$. 
 Si $\dist$ es distribución sobre $X$, lo notamos $x\sim \mathcal{D}$
\end{definition}

\begin{definition}[Espacio de probabilidad producto]
 Sean $(X_i, \Sigma_i, P_i)$ con $i=1,\ldots n$ espacios de probabilidad. Entonces decimos que:
 \[(X_1 \times \ldots \times X_n, \Sigma_1 \otimes \ldots \otimes \Sigma_n, P)\] es
 espacio de probabilidad producto asociado a $\Sigma_i$ y a $P_i$, $i=1, \ldots n$, si verifica:
 
 \begin{enumerate}[i]
  \item $\Sigma_1 \otimes \ldots \otimes \Sigma_n = \Sigma\left(\{A_1 \times \ldots \times A_n: A_i\in \Sigma_i\}\right)$
  \item $P(A_1 \times \ldots \times A_n) = \prod_{i=1}^n P_i(A_i)$, con $A_i\in \Sigma_i$ arbitrarios.
 \end{enumerate}
 
 $\mathcal{D}_1 \otimes \ldots \otimes \mathcal{D}_n := (\Sigma_1 \otimes \ldots \otimes \Sigma_n, P)$ recibe 
 el nombre de distribución de probabilidad producto.
 
 En el caso de $\Sigma_1 = \ldots = \Sigma_n$, notaremos $\Sigma^n$ a la $\sigma$-álgebra producto.
\end{definition}

El siguiente teorema nos dice que siempre podemos definir un espacio de probabilidad producto.

\begin{theorem}
 Sean $(X_i, \Sigma_i, P_i)$ con $i=1,\ldots n$ espacios de probabilidad. Entonces existe un espacio probabilidad
 producto.
 \[(X_1 \times \ldots \times X_n, \Sigma_1 \otimes \ldots \otimes \Sigma_n, P)\]
\end{theorem}
  \begin{proof}
   Sea $S$ la clase de rectángulos de la forma $A_1 \times A_2 \times \ldots \times A_n$ con $A_i$ conjunto 
   $\Sigma_i$-medible. $S$ es semianillo. Lo probamos para $n=2$ en la sección \ref{ex:rectangulos} (por inducción es 
   extensible a $n$ arbitrario). Haremos la demostración para $n=2$. Una obvia inducción en $n$ nos da el 
   resultado prara $n$ mayor que 2.
   
   Veamos que $P:S \rightarrow [0,+\infty]$ definida como $P(A\times B) = P_1(A) P_2(B)$ es medida sobre $S$.
   Claramente $P(\emptyset) = P_1(\emptyset)P_2(\emptyset) = 0$. Falta comprobar que dados $A_n \times B_n \in S$ 
   verificando $\sum_{n=1}^{+\infty} A_n\times B_n \in S$,
   es decir, $\sum_{n=1}^{+\infty} A_n\times B_n = A\times B$, con $A \in \Sigma_1$, $B \in \Sigma_2$, entonces
   \[P(A\times B) = \sum_{n=1}^{+\infty} P_1(A_n) P_2(B_n)\]
   
   Para cualquier $(x,y) \in X_1 \times X_2$, se tiene:
   \[
     \mathds{1}_{A\times B}(x,y) = \mathds{1}_{A}(x)\cdot \mathds{1}_B(y) = \sum_{n=1}^{+\infty} 
     \mathds{1}_{A_n\times B_n}(x,y) = \sum_{n=1}^{+\infty} \mathds{1}_{A_n}(x) \mathds{1}_{B_n}(y)
   \] 
   
   Fijado $y\in X_2$ $\left\{\sum_{i=1}^{n} \mathds{1}_{A_i}\mathds{1}_{B_i}(y)\right\}_n \nearrow \mathds{1}_A \mathds{1}_B(y)$ 
   puntualmente en $X_1$. Por el teorema de la convergencia monótona, integrando en $X_1$:
   \[\sum_{n=1}^{+\infty} P_1(A_n)\mathds{1}_{B_n}(y) = P_1(A) \mathds{1}_B(y)\]
   
   Como $\left\{\sum_{i=1}^{n} P_1(A_i)\mathds{1}_{B_i}\right\} \nearrow P_1(A) \mathds{1}_B$ puntualmente en $y\in X_2$, 
   integrando ahora en $X_2$ y aplicando teorema de convergencia monótona de nuevo, llegamos a:
   \[
     \sum_{n=1}^{+\infty} P_1(A_n) P_2(B_n) = P(A) P(B)
   \]
   
   En virtud del teorema \ref{th:caratheodory} de extensión de Caratheodory, como tenemos $S$ semianillo en 
   $X_1\times X_2$ y $P$ una medida en $S$, existe el espacio de probabilidad producto.
  \end{proof}

Se puede probar que el espacio probabilístico producto sólo hay uno, pero no usaremos este hecho. Obsérvese que cuando 
tengamos un espacio de probabilidad $(\Sigma, X)$ y consideramos que podemos extraer $m$ muestras del mismo
de manera independiente, estaremos sólo midiendo conjunto $A=A_1 \times A_2 \times \ldots \times A_n$, con $A_i \in\Sigma_i$.
Para estos sucesos siempre tendremos $\overline{P}(A) = \prod_{i=1}^n P(A_i)$ sea cual sea la distribución producto
$(\Sigma^n, \overline{P})$, pero conviene tener presente que es única.

\section{Desigualdades de concentración}
Para esta sección supondremos conocimiento previo de variables aleatorias. Sea $(X,\Sigma,P)$ un espacio 
de probabilidad en lo que sigue.

\begin{lemma}[Desigualdad de Markov]
Sea $W \ge 0$ una variable aleatoria. Entonces para todo $a > 0$ se verifica:
\[
  P[W \ge a] \le \frac{\expect(W)}{a}
\]
\label{ineq:markov}
\end{lemma}

\begin{proof}
 Se verifica $a\mathds{1}_{[W\ge a]} \le W$. Tomando esperanzas en ambos lados (ya que la esperanza es no 
 decreciente):
 \[
   aP[W\ge a] = a\expect(\mathds{1}_{[W\ge a]}) = \expect(a\mathds{1}_{[W\ge a]}) \le \expect(W)
 \]
 de donde se deduce el resultado, dividiendo por $a$.
\end{proof}

\begin{lemma}[Lema de Hoeffding]
 Sea $W$ una variable aleatoria con $a\le W \le b$ y $\expect(W) = 0$. Entonces para todo $\lambda > 0$:
 \[
   \expect(e^{\lambda W}) \le e^{\frac{\lambda^2(b-a)^2}{8}}
 \]
 
 \label{lemma:hoeffding}
\end{lemma}

\begin{proof}
 Supongamos $a=0$ o $b=0$. Entonces la desigualdad se cumpliría ya que se tendría $P[W=0]=1$. Por
 reducción al absurdo, en el caso $a=0$ si $P[W\ge 0] = 1$ y si se tuviera $P[W>0] > 0$ entonces $\mathbb{E}(W) > 0$.
 El caso $b=0$ es análogo.
 
 Con $a=0$ o $b=0$, tendríamos así $\expect(e^{\lambda W}) = \expect(1) = 1 = e^0 \le e^{\frac{\lambda^2 (b-a)^2}{8}}$, 
 por ser la exponencial monótona. 
 
 Supongamos pues en lo que sigue $a, b\neq 0$. Deberá ser $a < 0 < b$ por un argumento similar al
 primer caso.
 
 Por convexidad de $x\mapsto e^{\lambda x}$ con $a\le x \le b$, tenemos que:
 \[
   e^{\lambda W} \le \frac{b-W}{b-a} e^{\lambda a} + \frac{W-a}{b-a}e^{\lambda b}
 \]

 Tomando esperanzas en ambos términos: 
 \[
   \expect \left(e^{\lambda W}\right) \le \frac{b-\expect(W)}{b-a} e^{\lambda a} + 
   \frac{\expect(W)-a}{b-a}e^{\lambda b} = \frac{b}{b-a} e^{\lambda a} - \frac{a}{b-a} e^{\lambda b}
 \]
 
 Notando $t = \lambda(b-a), s = \frac{-a}{b-a}$, podemos definir $\varphi : \mathbb{R} \rightarrow \mathbb{R}$
 dada por $\varphi(t) = -st + \log(1-s+se^t)$ y se tiene:
 \[
   e^{\varphi(t)} = \frac{b}{b-a} e^{\lambda a} - \frac{a}{b-a} e^{\lambda b}
 \]
 
 Basta por tanto probar que $e^{\varphi(t)} \le e^{t^2/8}$.
 
 Se tiene $1-s+se^t = 1 + \frac{a}{b-a} - \frac{a}{b-a} e^t = \frac{b}{a-b} - \frac{a}{b-a} e^t > 0$, por
 ser $a< 0 < b$. Luego $\varphi\in \mathcal{C}^{\infty}$. Asímismo:
 \begin{align*}
  &\varphi(0) = 0 \\  
  & \varphi'(0) = \left.-s + \frac{se^t}{1-s+se^t} \right|_{t=0} = -s + \frac{s}{1-s+s} = 0\\
  & \varphi''(t) = \frac{se^t}{1-s+se^t} \left(1-\frac{se^t}{1-s+se^t}\right) = x(1-x) \le \frac{1}{4}
 \end{align*}
 
 Donde en la última desigualdad hemos usado que el polinomio $x-x^2$ tiene un máximo en $x=\frac{1}{2}$.
 
 Así, tomando $f(t) = \varphi(t) - \frac{1}{8}t^2$, tenemos que $f(0) = 0 = f'(0)$ y $f''(t) \le 0$. Es decir, 
 $f'(t) \ge 0$ para todo $t<0$ y $f'(t) \le 0$ para todo $t > 0$, luego $f$ tiene un máximo en $t=0$. Por tanto
 $f \le 0$ y $\varphi(t) \le \frac{1}{8} t^2$.
 \end{proof}


\begin{lemma}[Desigualdad de Hoeffding]
 Sean $W_1, \ldots W_m$ variables aleatorias i.i.d. (independiente e idénticamente distribuidas), tales que 
 $a_i \le W_i \le b_i$, y sea $\overline{W} = \frac{1}{m} \sum_{i=1}^m W_i$. Entonces dado $\varepsilon > 0$ arbitrario:
 \[
   P\left[\left| \overline{W} - \expect(\overline{W}) \right| > \varepsilon \right] \le 2e^{-2m^2 \frac{\varepsilon^2}{\sum_{i=1}^m (b_i-a_i)^2}}
 \]
 
 En el caso particular $a_i = a$ y $b_i = b$ para todo $i=1, \ldots m$:
 \[
   P\left[\left| \overline{W} - \expect(\overline{W}) \right| > \varepsilon \right] \le 2e^{-2m \left(\frac{\varepsilon}{b-a}\right)^2}
 \] 
 \label{ineq:hoeffding}
\end{lemma}

\begin{proof}
 Llamamos $V_i = W_i - \expect(W_i)$. Nótese que $\overline{V} = \overline{W} - \expect(W)$
 Aplicando monotonía de la función exponencial y la desigualdad de Markov \ref{ineq:markov}, tenemos que 
 para todo $\varepsilon, \lambda > 0$:
 \begin{equation}
 P[\overline{V} \ge \varepsilon] = P[e^{\lambda\overline{V}} \ge e^{\lambda \varepsilon}]
 \le e^{-\lambda \varepsilon} \expect(e^{\lambda \overline{V}})
 \label{eq:markov-hoeff}\tag{$\ast$}
 \end{equation}
 
 Además como las $W_i$ eran independientes, $e^{\lambda V_i}$ lo son, y se tiene:
 \[
   \expect(e^{\lambda V}) = \expect\left(\prod_{i=1}^m e^{\lambda V_i / m}\right) = \prod_{i=1}^m \expect(e^{\lambda V_i/m})
 \]
 
 Por otro lado tenemos:
 \begin{align}
  & \expect(V_i) = \expect(W_i) - \expect(\expect(W_i)) = \expect(W_i) - \expect(W_i) = 0 \nonumber \\
  & a_i-\expect(W_i) \le V_i \le b_i-\expect(W_i)
  \label{eq:prod-hoeff}\tag{$\ast\ast$}
 \end{align}
 
 Aplicando a cada $V_i/m$ el lema \ref{lemma:hoeffding}, desde \eqref{eq:markov-hoeff} y \eqref{eq:prod-hoeff} 
 llegamos a:
 \[
   \expect(e^{\lambda V}) \le e^{-\lambda \varepsilon} \cdot e^{\frac{\lambda^2 \sum_{i=1}^m(b_i-a_i)^2}{8m^2}} = 
   e^{\frac{\lambda^2 \sum_{i=1}^m(b_i-a_i)^2}{8m^2} - \lambda\varepsilon}
 \]
 y el polinomio $q(\lambda)= \frac{\lambda^2}{8m^2} \sum_{i=1}^m(b_i-a_i)^2 - \lambda\varepsilon$ se minimiza en 
 $\lambda = \frac{4m^2\varepsilon}{\sum_{i=1}^m(b_i-a_i)^2}$. Deducimos:
 \[
   P[\overline{V} \ge \varepsilon] \le e^{-2m^2 \frac{\varepsilon^2}{\sum_{i=1}^n (b_i-a_i)^2}}
 \]
 
 Análogamente se probaría:
 \[
   P[-\overline{V} \ge \varepsilon] \le e^{-2m^2 \frac{\varepsilon^2}{\sum_{i=1}^n (b_i-a_i)^2}}
 \]
 
 y por subaditividad: 
 \[
   P[|\overline{V}| > \varepsilon] \le P[\overline{V} \ge \varepsilon] + P[-\overline{V} \ge \varepsilon]
   \le 2e^{-2m^2 \frac{\varepsilon^2}{\sum_{i=1}^n (b_i-a_i)^2}}
 \]
 
\end{proof}
